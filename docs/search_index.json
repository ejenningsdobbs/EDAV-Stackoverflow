[["index.html", "Stack Overflow Tags Over Time Chapter 1 Introduction", " Stack Overflow Tags Over Time Emily Jennings-Dobbs and Yingyao Wu 2021-04-04 Chapter 1 Introduction "],["data-sources.html", "Chapter 2 Data sources", " Chapter 2 Data sources The data chosen for this project was a sample of posts from stackoverflow.com which is an online platform where people post questions about code and receive answers from the general public. The StackOverflow database is massive containing over 100 GB of information so for our purposes we will be taking a small sample from each year we are interested in. The data is split into 7 files, one for every year from 2015 to 2021. Each was queried from https://data.stackexchange.com/stackoverflow/queries using the query select Id, AcceptedAnswerId, CreationDate, LastActivityDate, Tags, AnswerCount, CommentCount, ViewCount, Title from Posts where year(CreationDate) = YEAR and Tags IS NOT NULL Where YEAR is replaced by the desired year. Each file contains the first 50,000 tagged posts on https://stackoverflow.com/ for the given year and contains the following variables; Id: the unique Id given to each post AcceptedAnswerId: The unique Id associated with an accepted answer CreationDate: The date and time each post was created LastAcvtivityDate: The most recent date in which someone interacted with the post as of 3/25/21 Tags: A list of tags associated with the post separated by angle brackets (“&lt;&gt;”) AnswerCount: the number of answers each post has received CommentCount: the number of comments each post has received ViewCount: the number of views each post has received Title: Title of the post as specified by the author "],["data-transformation.html", "Chapter 3 Data transformation", " Chapter 3 Data transformation The initial step in cleaning the data was to combine the 7 data frames each containing 50,000 observations into one data frame containing 300,000 observations. Now, there are three things that need to changed in our data before it can be used for this analysis; The Tags need to be separated so that we can compare the usage of each tag individually We need to create a new variable to indicate whether or not there was an accepted answer based off of whether or not we were supplied an AcceptedAnswerId which we will refer to as AcceptAnswer Convert AcceptAnswer, Tags and Id into factors, and convert CreationDate and LastActivityDate into dates For our purposes we can omit title since we already have the post Id as a source of identification and we can omit AcceptedAnswerId because we only need the frequency of accepted answers which we have identified in AcceptAnswer. "],["missing-values.html", "Chapter 4 Missing values", " Chapter 4 Missing values Since our query did not include values without tags, the only missing values in our dataset are the missing values in AcceptedAnswerId as a result of the question not being answered. This problem is solved by the introduction of the indicator variable AcceptAnswer. Each post can only have one accepted answer so if we wish to determine if any other variables have an impact on the probability that a post will have an accepted answer we can use the proportion of posts that have answered posts to find our results. That being said, not every tag we have listed in each year will appear in all the other years. Sampling random tags from our dataset proves unhelpful due to relatively low frequency of use of many of the tags within our sample. df &lt;- df %&gt;% mutate(year = as.factor(year(CreationDate))) unique_tags &lt;- df %&gt;% group_by(year) %&gt;% summarize(n_tags = length(unique(Tags))) set.seed(0) df_tab &lt;- sort(table(df$Tags), decreasing = T) sample_100 &lt;- sample(names(df_tab),100) newDF&lt;- df[which((df$Tags %in% sample_100)==TRUE),] ggplot(newDF, aes(x=year, y=Tags, fill = ViewCount)) + geom_tile() + ggtitle(&quot;100 Random Tags&quot;) Since we are not interested in all 29085 unique tags, it will suffice to analyze the top 50 most used unique tags for each year. This leaves us with 72 unique tags with which to analyze trends. df_tab &lt;- sort(table(df %&gt;% filter(year==2015) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_15 &lt;- names(df_tab[1:50]) df_tab &lt;- sort(table(df %&gt;% filter(year==2016) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_16 &lt;- names(df_tab[1:50]) df_tab &lt;- sort(table(df %&gt;% filter(year==2017) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_17 &lt;- names(df_tab[1:50]) df_tab &lt;- sort(table(df %&gt;% filter(year==2018) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_18 &lt;- names(df_tab[1:50]) df_tab &lt;- sort(table(df %&gt;% filter(year==2019) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_19 &lt;- names(df_tab[1:50]) df_tab &lt;- sort(table(df %&gt;% filter(year==2020) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_20 &lt;- names(df_tab[1:50]) df_tab &lt;- sort(table(df %&gt;% filter(year==2021) %&gt;% dplyr::select(Tags)), decreasing = T) top_50_21 &lt;- names(df_tab[1:50]) top_full &lt;- unique(c(top_50_15, top_50_16, top_50_17, top_50_18, top_50_19, top_50_20, top_50_21)) rm(top_50_15) rm(top_50_16) rm(top_50_17) rm(top_50_18) rm(top_50_19) rm(top_50_20) rm(top_50_21) df1 &lt;- df[which((df$Tags %in% top_full)==TRUE),] ggplot(df1, aes(x=year, y=Tags, fill = ViewCount)) + geom_tile() + ggtitle(&quot;50 Most Used Tags from Each Year &quot;) There is still have one tag (flutter), which isn’t used in all 7 years, however there should be enough data on the usage of these tags to compare them between the years. "],["results.html", "Chapter 5 Results 5.1 Top Tags over time", " Chapter 5 Results 5.1 Top Tags over time df1_count &lt;- df1 %&gt;% group_by(year, Tags) %&gt;% summarise(TotalViews = sum(ViewCount), TagCount = length(Tags), TotalComments = sum(CommentCount), AcceptedAnswers = sum(as.integer(as.character(AcceptAnswer))), TotalAnswers = sum(AnswerCount)) %&gt;% mutate(TagRank = as.factor(order(TagCount,year,Tags, decreasing = T))) initial_rank &lt;- df1_count %&gt;% filter(year==2015) %&gt;% dplyr::select(Tags, TagRank) initial_rank &lt;- initial_rank %&gt;% rename(InitialRank = TagRank) initial_rank &lt;- initial_rank[,2:3] df1_count &lt;- left_join(df1_count, initial_rank) %&gt;% mutate(InitialRank = cut(as.numeric(InitialRank), breaks = seq(0,75,5), right = F)) p &lt;- ggpairs(df1_count %&gt;% dplyr::select(year,TotalViews,TagCount,TotalComments, AcceptedAnswers,TotalAnswers), aes(color=year)) + theme_bw() + theme_update(text = element_text(size=15)) #scale colors for(i in 1:p$nrow) { for(j in 1:p$ncol){ p[i,j] &lt;- p[i,j] + scale_fill_manual(values=rev(c(&quot;#1B9E77&quot;, &quot;#D95F02&quot;, &quot;#7570B3&quot;, &quot;#E7298A&quot;, &quot;#66A61E&quot;, &quot;#E6AB02&quot;, &quot;#A6761D&quot;))) + scale_color_manual(values=rev(c(&quot;#1B9E77&quot;, &quot;#D95F02&quot;, &quot;#7570B3&quot;, &quot;#E7298A&quot;, &quot;#66A61E&quot;, &quot;#E6AB02&quot;, &quot;#A6761D&quot;))) } } p #TagCount, TotalComments, AcceptedAnswers, and TotalAnswers are all heavily correlated. Only need to use one or two to monitor the popularity of tags over years grid.arrange( df1_count %&gt;% dplyr::select(year, TotalComments, AcceptedAnswers, TotalAnswers) %&gt;% group_by(year) %&gt;% summarise_all(sum) %&gt;% gather(&quot;Type&quot;,&quot;Value&quot;,-year) %&gt;% ggplot(aes(year, Value, fill = Type)) + geom_bar(position = &quot;dodge&quot;, stat = &quot;identity&quot;) + scale_fill_manual(&quot;legend&quot;, values = c(&quot;TotalComments&quot; = &quot;#0072B2&quot;, &quot;AcceptedAnswers&quot; = &quot;#D55E00&quot;, &quot;TotalAnswers&quot; = &quot;#CC79A7&quot;)) + theme_bw() + ggtitle(&quot;Sum of Variables by Year&quot;), df1_count %&gt;% dplyr::select(year, TotalViews) %&gt;% group_by(year) %&gt;% summarise_all(sum) %&gt;% gather(&quot;Type&quot;,&quot;Value&quot;,-year) %&gt;% ggplot(aes(year, Value, fill = Type)) + geom_bar(position = &quot;dodge&quot;, stat = &quot;identity&quot;) + scale_fill_manual(&quot;legend&quot;, values = c(&quot;TotalViews&quot; = &quot;#E69F00&quot;)) + theme_bw(),ncol=1) #It appears views accumulate over time, total popularity/usage of tag may have to be computed overall. Current usage of Tag not reflected in views. Answers accumulate over time to a lesser degree. AcceptedAnswers seem to be pretty stable but haven&#39;t had time to fully accumulate for past 2 years. df1_count %&gt;% group_by(Tags) %&gt;% ggplot(aes(TotalViews, TotalAnswers)) + geom_hex() + ggtitle(&quot;Total Views vs Total Answers&quot;) + xlab(&quot;Total Views&quot;) + ylab(&quot;Total Answers&quot;) For tags with less than 5,000 answers, as the total number of views per tag increases, the total number of answers provided tend to increase as well, with an exception of a tag having about 5 million views but less than 1250 answers, which may be an outlier tag. This suggests that the more view a tag has, the more answers it is likely to have. Also, many of the tags have relatively low views and few answers. For tags that have more than 5,000 answers, the amount of views vary from lowest to greatest, suggesting little to no correlation between the number of views a tag in this group has and number of answers it has received. getPalette = colorRampPalette(brewer.pal(9, &quot;BuGn&quot;)) df1_count$Ranking&lt;-cut(as.numeric(df1_count$TagRank), seq(0,75,5), right=FALSE) colourCount = length(unique(df1_count$Ranking)) ggplot(df1_count, aes(x = year, stratum = TagRank, alluvium = Tags, fill = InitialRank, label = Tags)) + scale_fill_manual(values = rev(getPalette(colourCount))) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + geom_flow(stat = &quot;alluvium&quot;, lode.guidance = &quot;frontback&quot;, color = &quot;darkgray&quot;) + geom_stratum(width = 3/7) + geom_text(stat = &quot;alluvium&quot;, aes(label = after_stat(alluvium)), size=8) + theme(legend.position = &quot;bottom&quot;, axis.text = element_text(size = 15, face = &quot;bold&quot;)) + ggtitle(&quot;Frequency of Tags by Year&quot;) #Tags being used in new posts change drastically in popularity over time. Some notable trends include; amazon-web-services staying in the same rank over several years, android maintained rank for 3 years from 2018 to 2020 treemap(df1_count, index = c(&quot;year&quot;, &quot;Tags&quot;), vSize = &quot;TagCount&quot; ) treemap(df1_count, index = c(&quot;year&quot;, &quot;Tags&quot;), vSize = &quot;AcceptedAnswers&quot; ) #nearly identical but with notable differences; python and javascript always have a large proportion year2015 &lt;- df1_count %&gt;% group_by(Tags) %&gt;% filter(year == 2020) %&gt;% mutate(diff2015 = TagCount) %&gt;% dplyr::select(Tags, diff2015, TagCount) year2020 &lt;- df1_count %&gt;% group_by(Tags) %&gt;% filter(year == 2015) %&gt;% mutate(diff2020 = TagCount) %&gt;% dplyr::select(Tags, diff2020, TagCount) increase &lt;- full_join(year2015, year2020, &quot;Tags&quot;) %&gt;% group_by(Tags) %&gt;% mutate(diff = diff2020 - diff2015) %&gt;% mutate(increased = ifelse(diff &gt; 0, 1, 0)) %&gt;% dplyr::select(Tags, increased) df1_count_sub &lt;- df1_count %&gt;% filter(year %in% c(2015,2020)) df1_count_sub &lt;- left_join(df1_count_sub, increase, &quot;Tags&quot;) highlight &lt;- filter(df1_count_sub, increased == 0) df1_count_sub %&gt;% ggplot(aes(TagCount, fct_reorder(Tags, TagCount))) + geom_point(aes(color = year), alpha = 0.3) + geom_line(aes(group = Tags), alpha = 0.3) + geom_line(data = highlight, aes(group = Tags)) + geom_point(data = highlight, aes(color = year)) + ggtitle(&#39;Tag Counts in 2015 vs 2020&#39;) + xlab(&#39;Tag Count&#39;) + ylab(&#39;&#39;) + theme_bw() Highlighted tags are the ones with an increase from 2015 to 2020. From year 2015 to 2020, we can see python has gained a substantially large amount of interest by users based on the number of tags, and it is the only tag that has an increase in the top 12 tags with the most tag counts. Over the past five years, it seems like python has become the most popular programming language users have interacted with on StackOverflow in comparing to other languages such as javascript, java, c#, c++, which all have a decrease in the tag counts. languages &lt;- c(&quot;c&quot;,&quot;c#&quot;,&quot;c++&quot;,&quot;dart&quot;,&quot;java&quot;,&quot;javascript&quot;,&quot;sql&quot;,&quot;swift&quot;) df1_count %&gt;% filter(Tags %in% languages) %&gt;% ggplot(aes(TotalComments, fct_reorder(Tags, TotalComments))) + geom_density_ridges() + ggtitle(&quot;Total Comments by Tag&quot;) + ylab(&quot;Programming Languages&quot;) + xlab(&quot;Total Comments&quot;) + theme_classic() Based on the above Ridgeline plot, javascript, java, and c# seem to have the greatest variation in total comments from years 2015 to 2021. "],["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component df1_count &lt;- df1_count %&gt;% dplyr::select(Tags,year, TotalViews, TagCount, TotalComments, AcceptedAnswers, TagRank) %&gt;% mutate(year = as.factor(year)) parcoords(df1_count, rownames = FALSE, brushMode = &quot;1D-axes&quot;, reorderable = TRUE, queue = TRUE, alpha = 0.5, color = list(colorBy = &quot;TagRank&quot;, colorScale = &quot;scaleOrdinal&quot;, colorScheme = &quot;schemeCategory10&quot;), withD3 = TRUE) # &lt;head&gt; # &lt;title&gt;d3.js Canvas Parallel Coordinates&lt;/title&gt; # &lt;script src=&quot;http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js&quot;&gt;&lt;/script&gt; # &lt;script src=&quot;http://d3js.org/d3.v3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; # &lt;script src=&quot;http://underscorejs.org/underscore-min.js&quot;&gt;&lt;/script&gt; # &lt;script src=&quot;_include/js/lib/d3.parcoords.js&quot;&gt;&lt;/script&gt; # &lt;script src=&quot;_include/js/lib/d3.underscore.math.js&quot;&gt;&lt;/script&gt; # &lt;script src=&quot;_include/js/lib/d3.divgrid.js&quot;&gt;&lt;/script&gt; # &lt;link rel=&quot;stylesheet&quot; href=&quot;_include/css/fonts/droid.css&quot; type=&quot;text/css&quot; charset=&quot;utf-8&quot; /&gt; # &lt;link href=&quot;_include/css/d3.parcoords.css&quot; rel=&quot;stylesheet&quot;&gt; # &lt;link href=&quot;_include/css/bigdata.parallelcoordinates.css&quot; rel=&quot;stylesheet&quot;&gt; # &lt;/head&gt; # &lt;body&gt; # &lt;button id=&quot;keep-data&quot;&gt;Keep&lt;/button&gt; # &lt;button id=&quot;exclude-data&quot;&gt;Exclude&lt;/button&gt; # &lt;button id=&quot;reset-data&quot;&gt;Reset&lt;/button&gt; # &lt;br&gt; # &lt;div id=&quot;wrapper&quot; class=&quot;parcoords&quot; style=&quot;width:100%;height:340px&quot;&gt; # &lt;div id=&quot;desc&quot;&gt; # &lt;div id=&quot;title&quot;&gt;&lt;span class=&quot;large&quot;&gt;Parallel Coordinates&lt;/span&gt;&lt;/div&gt; # &lt;br&gt; # a d3.js visualisation using data from Stack Overflow # &lt;br&gt;&lt;br&gt;Drag around axis to begin brush&lt;br&gt; # Click axis to clear brush&lt;br&gt;Click a label to color data by z-scores # &lt;/div&gt; # &lt;/div&gt; # &lt;/body&gt; # &lt;div id=&quot;grid&quot;&gt;&lt;/div&gt; # &lt;script type=&quot;text/javascript&quot; src=&quot;_include/js/bigdata.parallelcoordinates.js&quot;&gt;&lt;/script&gt; "],["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion "]]
